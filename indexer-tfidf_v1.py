# -*- coding: utf-8 -*-
"""TFIDF_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hPGtHSd8HE75HtpUiQcWo5ZY3PCnwX4B
"""

# from google.colab import drive
# drive.mount('/content/drive')

# # install necessary libraries
# !pip install bs4 sqlitedict nltk requests

"""## TFIDF compilation"""

# # set directory for database storage
# import os
# os.chdir('/content/drive/MyDrive/BDT/CSIT Search Engine')


from sqlitedict import SqliteDict
import math

# read dictionaries 
url_to_pageID = SqliteDict('./app/db/url_to_pageID.sqlite')

# page body
body_forward_index = SqliteDict('./app/db/body_forward_index.sqlite')
body_inverted_index = SqliteDict('./app/db/body_inverted_index.sqlite')

# page title
title_forward_index = SqliteDict('./app/db/title_forward_index.sqlite')
title_inverted_index = SqliteDict('./app/db/title_inverted_index.sqlite')

# PageID to normalised value in page body
body_norm = SqliteDict('./app/db/body_norm.sqlite')
# PageID to normalised value in page title
title_norm = SqliteDict('./app/db/title_norm.sqlite')


def comp_tf_idf():
    i = 0
    for wordID, posting_list in body_inverted_index.items():
        i += 1
        if i%1000 ==0:
            print("calculating:", str(i), str(len(body_inverted_index)))
        df = float(len(posting_list))
        n = float(len(url_to_pageID))
        idf = math.log( n / df, 2)
        
        for pos in range(len(posting_list)):
            pageID = posting_list[pos][0]
            tf = float(posting_list[pos][1])
            tf_max = max(list(body_forward_index[pageID].values()))
            tf_idf = tf / tf_max * idf
            posting_list[pos][2] = tf_idf #insert tfidf in posting list
        body_inverted_index[wordID] = posting_list


def comp_tf_idf_title():
    i = 0
    for wordID, posting_list in title_inverted_index.items():
        i += 1
        if i%1000 ==0:
            print("calculating:", str(i), str(len(title_inverted_index)))      
        df = float(len(posting_list))
        n = float(len(url_to_pageID))  
        idf = math.log(n / df, 2)
        for pos in range(len(posting_list)):
            tf_idf = 1 * idf # assume tf = 1
            posting_list[pos][1] = tf_idf #insert title tfidf in posting list
        title_inverted_index[wordID] = posting_list


def comp_doc_norm():
    i = 0
    for pageID, fwd_dict in body_forward_index.items():
        i += 1
        if i%1000 ==0:
            print("calculating:", str(i), str(len(body_forward_index)))      
        
        word_list_page = list(fwd_dict.keys())
        doc_norm = 0
        for wordID in word_list_page:
            posting_list = body_inverted_index[wordID]
            doc_list_ID = [pl[0] for pl in posting_list] #to obtain pageID containing the word
            index = doc_list_ID.index(int(pageID)) 
            tf_idf = posting_list[index][2] #retrieve tfidf for selected pageID
            doc_norm += tf_idf * tf_idf
        
        doc_norm = math.sqrt(doc_norm)
        body_norm[pageID] = doc_norm


def comp_title_norm():
    i = 0
    for doc_id, fwd_list in title_forward_index.items():
        i += 1
        if i%1000 ==0:
            print("calculating:", str(i), str(len(title_forward_index)))  

        title_doc_norm = 0
        for wordID in fwd_list:
            posting_list = title_inverted_index[wordID]
            doc_list_ID = [p_l[0] for p_l in posting_list] #to obtain pageID containing the word
            index = doc_list_ID.index(int(doc_id))
            tf_idf = posting_list[index][1] #retrieve tfidf for selected pageID
            title_doc_norm += tf_idf * tf_idf
        title_doc_norm = math.sqrt(title_doc_norm)
        title_norm[doc_id] = title_doc_norm

comp_tf_idf()

comp_tf_idf_title()

comp_doc_norm()

comp_title_norm()


body_inverted_index.commit()
title_inverted_index.commit()
body_norm.commit()
title_norm.commit()

url_to_pageID.close()
body_forward_index.close()
title_forward_index.close()

body_inverted_index.close()
body_norm.close()
title_inverted_index.close()
title_norm.close()

